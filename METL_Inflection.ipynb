{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabrice-camus/UNIGE-MA2a-METL-Projet-Inflection/blob/master/METL_Inflection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_5IYD3mFfQC"
      },
      "source": [
        "# METL // Projet - Morphological Inflection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gjbIORxFa8Z"
      },
      "source": [
        "author = \"Fabrice Camus\"\n",
        "\n",
        "module = \"METL // SP 2021-2022\"\n",
        "\n",
        "version = \"1.0\"\n",
        "\n",
        "date = \"24.03.2022\"\n",
        "\n",
        "description = \"Given a lemma and POS, generate an inflected form, by using a seq2seq model\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Clone GitHub Repository"
      ],
      "metadata": {
        "id": "4HfPw_mTdEfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo = 'UNIGE-MA2a-METL-Projet-Inflection'"
      ],
      "metadata": {
        "id": "QGFELmKNdiO2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fabrice-camus/{repo}.git"
      ],
      "metadata": {
        "id": "V9pvl5PPc5tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {repo}"
      ],
      "metadata": {
        "id": "lDORjtg3dUq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be6dee3-cc88-4c3a-c2b2-23671bcf8958"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UNIGE-MA2a-METL-Projet-Inflection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzNbjckOBhmz"
      },
      "source": [
        "#2. Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "oIzxPkPehs8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SbYCZpitkR11"
      },
      "outputs": [],
      "source": [
        "# MorphoInflection_dataset\n",
        "\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from itertools import zip_longest\n",
        "\n",
        "\n",
        "START_CHAR ='<'\n",
        "END_CHAR ='>'\n",
        "EMPTY_CHAR =''\n",
        "\n",
        "#Pad two lists to have same length\n",
        "def pad(*lists, padding=0):\n",
        "    padded = [[] for _ in lists]\n",
        "\n",
        "    for lst in zip_longest(*lists, fillvalue=padding):\n",
        "        for i, elem in enumerate(lst):\n",
        "            padded[i].append(elem)\n",
        "\n",
        "    return padded\n",
        "\n",
        "#custom collate for batch creation (dataloader)\n",
        "def my_custom_collate(data):\n",
        "    # data is a list of tuples\n",
        "    x = [torch.tensor(d[0],dtype=torch.long) for d in data]\n",
        "    y = [torch.tensor(d[1],dtype=torch.long) for d in data]\n",
        "    x = pad_sequence(x, batch_first=True)\n",
        "    y = pad_sequence(y, batch_first=True)\n",
        "    l = [d[2] for d in data]\n",
        "    msd = [d[3] for d in data]\n",
        "    return x,y,l, msd\n",
        "\n",
        "\n",
        "class MorphoInflectionDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    super(MorphoInflectionDataset, self).__init__()\n",
        "    self.token2id={}\n",
        "    self.token2id[EMPTY_CHAR] = 0\n",
        "    self.token2id[START_CHAR] = 1\n",
        "    self.token2id[END_CHAR] = 2\n",
        "\n",
        "    self.id2token=[]\n",
        "    self.vocab_size=0\n",
        "\n",
        "\n",
        "  # load file and extract lines\n",
        "  def create_dataset(self,filename):\n",
        "    #file is encoded in utf-8 \n",
        "    with open(filename, encoding='utf_8') as f:\n",
        "      lines = f.readlines()\n",
        "      lines = [line.rstrip() for line in lines]\n",
        "     \n",
        "    #load raw data\n",
        "    self.corpus = lines\n",
        "    # create/update vocabulary and input/output in text format\n",
        "    self.input, self.output, self.lemmas, self.msd = self.__build_raw_data__()\n",
        "    #size of vocabulary\n",
        "    self.vocab_size = len(self.token2id)\n",
        "\n",
        "    # create a vector with token's id instead of text\n",
        "    self.input_id = [self.__tokens2id__(input) for input in self.input]\n",
        "    self.output_id = [self.__tokens2id__(output) for output in self.output]\n",
        "\n",
        "    # pad to have same length    \n",
        "    for i in range(len(self.input_id)):\n",
        "      self.input_id[i-1], self.output_id[i-1] = pad(self.input_id[i-1], self.output_id[i-1])\n",
        "\n",
        "\n",
        "  # create/update vocabulary, input and output raw data\n",
        "  def __build_raw_data__(self):\n",
        "  \n",
        "    #start index\n",
        "    index=len(self.token2id)\n",
        "    lemmas=[]\n",
        "    msds=[]\n",
        "    input = []\n",
        "    output = []\n",
        "    # extract token (char) and construct all we need\n",
        "    for line in self.corpus:\n",
        "      \n",
        "      datas=line.split('\\t')\n",
        "      \n",
        "      lemma=datas[0]\n",
        "      lemmas.append(lemma)\n",
        "      msd=datas[1]\n",
        "      msds.append(msd)\n",
        "      inflected_form=datas[2]\n",
        "      \n",
        "      lemma_chars=[]\n",
        "      \n",
        "      #split ääkköstää into char list\n",
        "      for c in lemma:\n",
        "        lemma_chars.append(c)\n",
        "        if c not in self.token2id:\n",
        "          self.token2id[c]=index\n",
        "          index+=1\n",
        "      \n",
        "      #idem for inflected form\n",
        "      inflected_form_chars = []\n",
        "      for c in inflected_form:\n",
        "        inflected_form_chars.append(c)\n",
        "        if c not in self.token2id:\n",
        "          self.token2id[c]=index\n",
        "          index+=1\n",
        "      \n",
        "\n",
        "      #extract POS-TAG : each pos-tag is a token \n",
        "      msd_tags=msd.split(',')\n",
        "      for tag in msd_tags:\n",
        "        if tag not in self.token2id:\n",
        "          self.token2id[tag]=index\n",
        "          index+=1\n",
        "        #pad with empty char at beginning to have a alignement POS-TAG->''\n",
        "        inflected_form_chars.insert(0,EMPTY_CHAR)\n",
        "\n",
        "      #concat to construct final x and y in training data\n",
        "      input_final=[*msd_tags,*lemma_chars]\n",
        "      input_final.insert(0,START_CHAR)\n",
        "      input_final.append(END_CHAR)\n",
        "      inflected_form_chars.insert(0,START_CHAR)\n",
        "      inflected_form_chars.append(END_CHAR)\n",
        "\n",
        "      input.append(input_final)\n",
        "      output.append(inflected_form_chars)\n",
        "\n",
        "\n",
        "    # token list\n",
        "    self.id2token = list(self.token2id.keys())\n",
        "    \n",
        "    return input, output, lemmas, msds \n",
        "\n",
        "\n",
        "  def __tokens2id__(self,tokens):\n",
        "      return [self.token2id[token] for token in tokens]\n",
        "\n",
        "\n",
        "  # len of train_data\n",
        "  # must be implemented\n",
        "  def __len__(self):\n",
        "    return len(self.input_id) \n",
        "\n",
        "  # return x and y\n",
        "  # must be implemented\n",
        "  def __getitem__(self, idx):\n",
        "    x = self.input_id[idx]\n",
        "    y = self.output_id[idx]\n",
        "    lemma = self.lemmas[idx]\n",
        "    msd = self.msd[idx]\n",
        "    #tuple (x,y)\n",
        "    return x, y, lemma, msd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Sz82NjtfogHE"
      },
      "outputs": [],
      "source": [
        "train_dataset = MorphoInflectionDataset()\n",
        "train_dataset.create_dataset('./data/finnish-task1-train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6IIOo01xP8U"
      },
      "outputs": [],
      "source": [
        "# data sample count\n",
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNDqRPB2q70_"
      },
      "outputs": [],
      "source": [
        "# vocabulary\n",
        "train_dataset.token2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjHQlidhrc5M"
      },
      "outputs": [],
      "source": [
        "train_dataset.id2token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ysewe97drdVT"
      },
      "outputs": [],
      "source": [
        "# vocabulary size\n",
        "len(train_dataset.token2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8JJMatkdvx81"
      },
      "outputs": [],
      "source": [
        "# DataLoader is useful for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=my_custom_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xi8fJNlBl9u"
      },
      "source": [
        "#3. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oNg156bqOERg"
      },
      "outputs": [],
      "source": [
        "# MorphoInflection_model\n",
        "\n",
        "#help : https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
        "#help : https://towardsdatascience.com/a-comprehensive-guide-to-neural-machine-translation-using-seq2sequence-modelling-using-pytorch-41c9b84ba350#2c97\n",
        "\n",
        "\n",
        "from torch.nn import Module\n",
        "from torch.nn import Embedding\n",
        "from torch.nn import LSTM\n",
        "from torch.nn import Linear\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "\n",
        "class morphological_inflection_seq2seq(Module):\n",
        "\n",
        "  def __init__(self, embedding_dim, hidden_size, vocab_size):\n",
        "    super(morphological_inflection_seq2seq, self).__init__()\n",
        "\n",
        "    # vocabulary size (int)\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "    # Embeddings dimensions (int)\n",
        "    self.embedding_size = embedding_dim\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell (int)\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    #--------------\n",
        "    # Encoder\n",
        "    #--------------\n",
        "    \n",
        "    # Embeddings : create a matrix of VxD\n",
        "    # shape(vocab_size,emb_dim)\n",
        "    # Embedding(72, 10)\n",
        "    self.inputs_embeds = Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embedding_size, padding_idx=0)\n",
        "    \n",
        "\n",
        "    # LSTM(10, 50)\n",
        "    self.lstm_encoder = LSTM(self.embedding_size, self.hidden_size, batch_first=True)\n",
        "\n",
        "    #--------------\n",
        "    # Decoder\n",
        "    #--------------\n",
        "    \n",
        "    # 72\n",
        "    self.output_size = vocab_size\n",
        "\n",
        "    # Embeddings : create a matrix of VxD\n",
        "    # (vocab_size,emb_dim)\n",
        "    self.output_embeds = Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embedding_size, padding_idx=0)\n",
        "    self.lstm_decoder = LSTM(self.embedding_size, self.hidden_size, batch_first=True)\n",
        "    #linear layer with input = hidden_size\n",
        "    #out_features = voc size -> so that we can apply a softmax activation function\n",
        "    #Linear(in_features=50, out_features=72, bias=True)\n",
        "    self.hidden2vocab = Linear(self.hidden_size, self.vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, batch, forceTeaching=False):\n",
        "      \n",
        "      # # x : list of n tensor (n=batch_size)\n",
        "      #x[i] : 1 x sample [ 1,  9, 10,  ...,  0,  0,  0]\n",
        "      x,y,_,_ = batch\n",
        "      \n",
        "      #batch_size x seq_len\n",
        "      y_matrix = np.array(y)\n",
        "\n",
        "      #--------------\n",
        "      # Encoder part\n",
        "      #--------------\n",
        "\n",
        "      # Emmbeddings\n",
        "      # torch.Size([batch_size, sequence_len, emb_dim])\n",
        "      # torch.Size([64, 26, 10])\n",
        "      embeds = self.inputs_embeds(x)\n",
        "\n",
        "      # pass embeds to lstm\n",
        "      # encoder_outputs : we don't care // torch.Size([batch_size, sequence_len, hidden_dim])\n",
        "      # encoder_hidden_state : last hiddend state which contains our input representation\n",
        "      # encoder_hidden_state: tuple(hidden state,cell state)\n",
        "      # hidden_state/cell_state : torch.Size([1, batch_size, hidden dim]) // torch.Size([1, 64, 50])\n",
        "      # 1 = unidirectionnel, 2 : bidir\n",
        "      encoder_outputs, encoder_hidden_state = self.lstm_encoder(embeds)\n",
        "\n",
        "\n",
        "      #--------------\n",
        "      # Decoder part\n",
        "      #--------------\n",
        "      # y : list of n tensors (n=batch_size)\n",
        "      #y[i] : 1 x sample [1, 0, 0,  ..., 2, 0, 0]\n",
        "      # ex : 26      \n",
        "      sequence_length = y_matrix.shape[1]\n",
        "      batch_size= y_matrix.shape[0]\n",
        "\n",
        "      # decoder lstm will receive hidden_state of encoder\n",
        "      hidden_state = encoder_hidden_state\n",
        "      # tensor for whole outputs --> contains id of predicted inflected form\n",
        "      # shape [seq_len, batch_size, self.vocab_size] //torch.Size([26, 64,72])\n",
        "      outputs = torch.zeros(sequence_length,batch_size,self.vocab_size)\n",
        "\n",
        "      #one char\n",
        "      #shape(batch_size,1)\n",
        "      token=y[:,[0]]\n",
        "      \n",
        "      \n",
        "      # for each char in y, call lstm to predict next char\n",
        "      # teach forcing --> give to next loop gold char (from y) and not predicted char\n",
        "      for i in range(1, sequence_length):\n",
        "\n",
        "        embeds = self.output_embeds(token)     \n",
        "        #LSTM layer\n",
        "        #output shape :[batch_size, seq_len, hidden size] torch.Size([64, 1, 50])\n",
        "        output, hidden_state = self.lstm_decoder(embeds, hidden_state)\n",
        "        \n",
        "        \n",
        "        #output : prediction of next token \n",
        "        #shape [batch_size,seq_len, vocab_size] // torch.Size([64, 1, 72])\n",
        "        prediction = self.hidden2vocab(output)\n",
        "\n",
        "        #shape [batch_size, vocab_size] // torch.Size([64, 72])\n",
        "        prediction = prediction.squeeze(1)\n",
        "\n",
        "        #torch.Size([64,72])\n",
        "        prediction_probs = softmax(prediction,1)\n",
        "       \n",
        "        outputs[i]=prediction_probs\n",
        "\n",
        "        # teacher forcing : next input in lstm isn't the predicted token, but the gold token (from y)\n",
        "        if forceTeaching:\n",
        "          token = y[:,[i]] \n",
        "        else:\n",
        "          #next token is the predicted token\n",
        "          token = torch.argmax(prediction_probs,1).view(prediction_probs.shape[0],1)\n",
        "          \n",
        "         \n",
        "\n",
        "\n",
        "      # -->seq_len, batch_size, self.vocab_size\n",
        "      outputs=torch.moveaxis(outputs,0,2)\n",
        "      return outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Training"
      ],
      "metadata": {
        "id": "RMdOXAFueW1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "R-eUEsOsUuIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52052e1-f6a8-4931-be9a-5af5815ae8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch (1/10) -  Batch (1/25])\n",
            "Epoch (1/10) -  Batch (2/25])\n",
            "Epoch (1/10) -  Batch (3/25])\n",
            "Epoch (1/10) -  Batch (4/25])\n",
            "Epoch (1/10) -  Batch (5/25])\n",
            "Epoch (1/10) -  Batch (6/25])\n",
            "Epoch (1/10) -  Batch (7/25])\n",
            "Epoch (1/10) -  Batch (8/25])\n",
            "Epoch (1/10) -  Batch (9/25])\n",
            "Epoch (1/10) -  Batch (10/25])\n",
            "Epoch (1/10) -  Batch (11/25])\n",
            "Epoch (1/10) -  Batch (12/25])\n",
            "Epoch (1/10) -  Batch (13/25])\n",
            "Epoch (1/10) -  Batch (14/25])\n",
            "Epoch (1/10) -  Batch (15/25])\n",
            "Epoch (1/10) -  Batch (16/25])\n",
            "Epoch (1/10) -  Batch (17/25])\n",
            "Epoch (1/10) -  Batch (18/25])\n",
            "Epoch (1/10) -  Batch (19/25])\n",
            "Epoch (1/10) -  Batch (20/25])\n",
            "Epoch (1/10) -  Batch (21/25])\n",
            "Epoch (1/10) -  Batch (22/25])\n",
            "Epoch (1/10) -  Batch (23/25])\n",
            "Epoch (1/10) -  Batch (24/25])\n",
            "Epoch (1/10) -  Batch (25/25])\n",
            "Epoch (2/10) -  Batch (1/25])\n",
            "Epoch (2/10) -  Batch (2/25])\n",
            "Epoch (2/10) -  Batch (3/25])\n",
            "Epoch (2/10) -  Batch (4/25])\n",
            "Epoch (2/10) -  Batch (5/25])\n",
            "Epoch (2/10) -  Batch (6/25])\n",
            "Epoch (2/10) -  Batch (7/25])\n",
            "Epoch (2/10) -  Batch (8/25])\n",
            "Epoch (2/10) -  Batch (9/25])\n",
            "Epoch (2/10) -  Batch (10/25])\n",
            "Epoch (2/10) -  Batch (11/25])\n",
            "Epoch (2/10) -  Batch (12/25])\n",
            "Epoch (2/10) -  Batch (13/25])\n",
            "Epoch (2/10) -  Batch (14/25])\n",
            "Epoch (2/10) -  Batch (15/25])\n",
            "Epoch (2/10) -  Batch (16/25])\n",
            "Epoch (2/10) -  Batch (17/25])\n",
            "Epoch (2/10) -  Batch (18/25])\n",
            "Epoch (2/10) -  Batch (19/25])\n",
            "Epoch (2/10) -  Batch (20/25])\n",
            "Epoch (2/10) -  Batch (21/25])\n",
            "Epoch (2/10) -  Batch (22/25])\n",
            "Epoch (2/10) -  Batch (23/25])\n",
            "Epoch (2/10) -  Batch (24/25])\n",
            "Epoch (2/10) -  Batch (25/25])\n",
            "Epoch (3/10) -  Batch (1/25])\n",
            "Epoch (3/10) -  Batch (2/25])\n",
            "Epoch (3/10) -  Batch (3/25])\n",
            "Epoch (3/10) -  Batch (4/25])\n",
            "Epoch (3/10) -  Batch (5/25])\n",
            "Epoch (3/10) -  Batch (6/25])\n",
            "Epoch (3/10) -  Batch (7/25])\n",
            "Epoch (3/10) -  Batch (8/25])\n",
            "Epoch (3/10) -  Batch (9/25])\n",
            "Epoch (3/10) -  Batch (10/25])\n",
            "Epoch (3/10) -  Batch (11/25])\n",
            "Epoch (3/10) -  Batch (12/25])\n",
            "Epoch (3/10) -  Batch (13/25])\n",
            "Epoch (3/10) -  Batch (14/25])\n",
            "Epoch (3/10) -  Batch (15/25])\n",
            "Epoch (3/10) -  Batch (16/25])\n",
            "Epoch (3/10) -  Batch (17/25])\n",
            "Epoch (3/10) -  Batch (18/25])\n",
            "Epoch (3/10) -  Batch (19/25])\n",
            "Epoch (3/10) -  Batch (20/25])\n",
            "Epoch (3/10) -  Batch (21/25])\n",
            "Epoch (3/10) -  Batch (22/25])\n",
            "Epoch (3/10) -  Batch (23/25])\n",
            "Epoch (3/10) -  Batch (24/25])\n",
            "Epoch (3/10) -  Batch (25/25])\n",
            "Epoch (4/10) -  Batch (1/25])\n",
            "Epoch (4/10) -  Batch (2/25])\n",
            "Epoch (4/10) -  Batch (3/25])\n",
            "Epoch (4/10) -  Batch (4/25])\n",
            "Epoch (4/10) -  Batch (5/25])\n",
            "Epoch (4/10) -  Batch (6/25])\n",
            "Epoch (4/10) -  Batch (7/25])\n",
            "Epoch (4/10) -  Batch (8/25])\n",
            "Epoch (4/10) -  Batch (9/25])\n",
            "Epoch (4/10) -  Batch (10/25])\n",
            "Epoch (4/10) -  Batch (11/25])\n",
            "Epoch (4/10) -  Batch (12/25])\n",
            "Epoch (4/10) -  Batch (13/25])\n",
            "Epoch (4/10) -  Batch (14/25])\n",
            "Epoch (4/10) -  Batch (15/25])\n",
            "Epoch (4/10) -  Batch (16/25])\n",
            "Epoch (4/10) -  Batch (17/25])\n",
            "Epoch (4/10) -  Batch (18/25])\n",
            "Epoch (4/10) -  Batch (19/25])\n",
            "Epoch (4/10) -  Batch (20/25])\n",
            "Epoch (4/10) -  Batch (21/25])\n",
            "Epoch (4/10) -  Batch (22/25])\n",
            "Epoch (4/10) -  Batch (23/25])\n",
            "Epoch (4/10) -  Batch (24/25])\n",
            "Epoch (4/10) -  Batch (25/25])\n",
            "Epoch (5/10) -  Batch (1/25])\n",
            "Epoch (5/10) -  Batch (2/25])\n",
            "Epoch (5/10) -  Batch (3/25])\n",
            "Epoch (5/10) -  Batch (4/25])\n",
            "Epoch (5/10) -  Batch (5/25])\n",
            "Epoch (5/10) -  Batch (6/25])\n",
            "Epoch (5/10) -  Batch (7/25])\n",
            "Epoch (5/10) -  Batch (8/25])\n",
            "Epoch (5/10) -  Batch (9/25])\n",
            "Epoch (5/10) -  Batch (10/25])\n",
            "Epoch (5/10) -  Batch (11/25])\n",
            "Epoch (5/10) -  Batch (12/25])\n",
            "Epoch (5/10) -  Batch (13/25])\n",
            "Epoch (5/10) -  Batch (14/25])\n",
            "Epoch (5/10) -  Batch (15/25])\n",
            "Epoch (5/10) -  Batch (16/25])\n",
            "Epoch (5/10) -  Batch (17/25])\n",
            "Epoch (5/10) -  Batch (18/25])\n",
            "Epoch (5/10) -  Batch (19/25])\n",
            "Epoch (5/10) -  Batch (20/25])\n",
            "Epoch (5/10) -  Batch (21/25])\n",
            "Epoch (5/10) -  Batch (22/25])\n",
            "Epoch (5/10) -  Batch (23/25])\n",
            "Epoch (5/10) -  Batch (24/25])\n",
            "Epoch (5/10) -  Batch (25/25])\n",
            "Epoch (6/10) -  Batch (1/25])\n",
            "Epoch (6/10) -  Batch (2/25])\n",
            "Epoch (6/10) -  Batch (3/25])\n",
            "Epoch (6/10) -  Batch (4/25])\n",
            "Epoch (6/10) -  Batch (5/25])\n",
            "Epoch (6/10) -  Batch (6/25])\n",
            "Epoch (6/10) -  Batch (7/25])\n",
            "Epoch (6/10) -  Batch (8/25])\n",
            "Epoch (6/10) -  Batch (9/25])\n",
            "Epoch (6/10) -  Batch (10/25])\n",
            "Epoch (6/10) -  Batch (11/25])\n",
            "Epoch (6/10) -  Batch (12/25])\n",
            "Epoch (6/10) -  Batch (13/25])\n",
            "Epoch (6/10) -  Batch (14/25])\n",
            "Epoch (6/10) -  Batch (15/25])\n",
            "Epoch (6/10) -  Batch (16/25])\n",
            "Epoch (6/10) -  Batch (17/25])\n",
            "Epoch (6/10) -  Batch (18/25])\n",
            "Epoch (6/10) -  Batch (19/25])\n",
            "Epoch (6/10) -  Batch (20/25])\n",
            "Epoch (6/10) -  Batch (21/25])\n",
            "Epoch (6/10) -  Batch (22/25])\n",
            "Epoch (6/10) -  Batch (23/25])\n",
            "Epoch (6/10) -  Batch (24/25])\n",
            "Epoch (6/10) -  Batch (25/25])\n",
            "Epoch (7/10) -  Batch (1/25])\n",
            "Epoch (7/10) -  Batch (2/25])\n",
            "Epoch (7/10) -  Batch (3/25])\n",
            "Epoch (7/10) -  Batch (4/25])\n",
            "Epoch (7/10) -  Batch (5/25])\n",
            "Epoch (7/10) -  Batch (6/25])\n",
            "Epoch (7/10) -  Batch (7/25])\n",
            "Epoch (7/10) -  Batch (8/25])\n",
            "Epoch (7/10) -  Batch (9/25])\n",
            "Epoch (7/10) -  Batch (10/25])\n",
            "Epoch (7/10) -  Batch (11/25])\n",
            "Epoch (7/10) -  Batch (12/25])\n",
            "Epoch (7/10) -  Batch (13/25])\n",
            "Epoch (7/10) -  Batch (14/25])\n",
            "Epoch (7/10) -  Batch (15/25])\n",
            "Epoch (7/10) -  Batch (16/25])\n",
            "Epoch (7/10) -  Batch (17/25])\n",
            "Epoch (7/10) -  Batch (18/25])\n",
            "Epoch (7/10) -  Batch (19/25])\n",
            "Epoch (7/10) -  Batch (20/25])\n",
            "Epoch (7/10) -  Batch (21/25])\n",
            "Epoch (7/10) -  Batch (22/25])\n",
            "Epoch (7/10) -  Batch (23/25])\n",
            "Epoch (7/10) -  Batch (24/25])\n",
            "Epoch (7/10) -  Batch (25/25])\n",
            "Epoch (8/10) -  Batch (1/25])\n",
            "Epoch (8/10) -  Batch (2/25])\n",
            "Epoch (8/10) -  Batch (3/25])\n",
            "Epoch (8/10) -  Batch (4/25])\n",
            "Epoch (8/10) -  Batch (5/25])\n",
            "Epoch (8/10) -  Batch (6/25])\n",
            "Epoch (8/10) -  Batch (7/25])\n",
            "Epoch (8/10) -  Batch (8/25])\n",
            "Epoch (8/10) -  Batch (9/25])\n",
            "Epoch (8/10) -  Batch (10/25])\n",
            "Epoch (8/10) -  Batch (11/25])\n",
            "Epoch (8/10) -  Batch (12/25])\n",
            "Epoch (8/10) -  Batch (13/25])\n",
            "Epoch (8/10) -  Batch (14/25])\n",
            "Epoch (8/10) -  Batch (15/25])\n",
            "Epoch (8/10) -  Batch (16/25])\n",
            "Epoch (8/10) -  Batch (17/25])\n",
            "Epoch (8/10) -  Batch (18/25])\n",
            "Epoch (8/10) -  Batch (19/25])\n",
            "Epoch (8/10) -  Batch (20/25])\n",
            "Epoch (8/10) -  Batch (21/25])\n",
            "Epoch (8/10) -  Batch (22/25])\n",
            "Epoch (8/10) -  Batch (23/25])\n",
            "Epoch (8/10) -  Batch (24/25])\n",
            "Epoch (8/10) -  Batch (25/25])\n",
            "Epoch (9/10) -  Batch (1/25])\n",
            "Epoch (9/10) -  Batch (2/25])\n",
            "Epoch (9/10) -  Batch (3/25])\n",
            "Epoch (9/10) -  Batch (4/25])\n",
            "Epoch (9/10) -  Batch (5/25])\n",
            "Epoch (9/10) -  Batch (6/25])\n",
            "Epoch (9/10) -  Batch (7/25])\n",
            "Epoch (9/10) -  Batch (8/25])\n",
            "Epoch (9/10) -  Batch (9/25])\n",
            "Epoch (9/10) -  Batch (10/25])\n",
            "Epoch (9/10) -  Batch (11/25])\n",
            "Epoch (9/10) -  Batch (12/25])\n",
            "Epoch (9/10) -  Batch (13/25])\n",
            "Epoch (9/10) -  Batch (14/25])\n",
            "Epoch (9/10) -  Batch (15/25])\n",
            "Epoch (9/10) -  Batch (16/25])\n",
            "Epoch (9/10) -  Batch (17/25])\n",
            "Epoch (9/10) -  Batch (18/25])\n",
            "Epoch (9/10) -  Batch (19/25])\n",
            "Epoch (9/10) -  Batch (20/25])\n",
            "Epoch (9/10) -  Batch (21/25])\n",
            "Epoch (9/10) -  Batch (22/25])\n",
            "Epoch (9/10) -  Batch (23/25])\n",
            "Epoch (9/10) -  Batch (24/25])\n",
            "Epoch (9/10) -  Batch (25/25])\n",
            "Epoch (10/10) -  Batch (1/25])\n",
            "Epoch (10/10) -  Batch (2/25])\n",
            "Epoch (10/10) -  Batch (3/25])\n",
            "Epoch (10/10) -  Batch (4/25])\n",
            "Epoch (10/10) -  Batch (5/25])\n",
            "Epoch (10/10) -  Batch (6/25])\n",
            "Epoch (10/10) -  Batch (7/25])\n",
            "Epoch (10/10) -  Batch (8/25])\n",
            "Epoch (10/10) -  Batch (9/25])\n",
            "Epoch (10/10) -  Batch (10/25])\n",
            "Epoch (10/10) -  Batch (11/25])\n",
            "Epoch (10/10) -  Batch (12/25])\n",
            "Epoch (10/10) -  Batch (13/25])\n",
            "Epoch (10/10) -  Batch (14/25])\n",
            "Epoch (10/10) -  Batch (15/25])\n",
            "Epoch (10/10) -  Batch (16/25])\n",
            "Epoch (10/10) -  Batch (17/25])\n",
            "Epoch (10/10) -  Batch (18/25])\n",
            "Epoch (10/10) -  Batch (19/25])\n",
            "Epoch (10/10) -  Batch (20/25])\n",
            "Epoch (10/10) -  Batch (21/25])\n",
            "Epoch (10/10) -  Batch (22/25])\n",
            "Epoch (10/10) -  Batch (23/25])\n",
            "Epoch (10/10) -  Batch (24/25])\n",
            "Epoch (10/10) -  Batch (25/25])\n"
          ]
        }
      ],
      "source": [
        "##Training\n",
        "\n",
        "from torch.optim import SGD, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "# Model\n",
        "emb_dim=10\n",
        "hidden_dim=50\n",
        "morpho_inflection_model = morphological_inflection_seq2seq(emb_dim, hidden_dim, train_dataset.vocab_size)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = SGD(morpho_inflection_model.parameters(), lr=0.1)\n",
        "\n",
        "# Loss\n",
        "cross_entropy_loss = CrossEntropyLoss()\n",
        "\n",
        "# Hyper-params\n",
        "num_epochs = 20000\n",
        "num_epochs = 10\n",
        "\n",
        "# Metrics\n",
        "losses_epoch_train = []\n",
        "\n",
        "\n",
        "\n",
        "# Loop\n",
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  morpho_inflection_model.train()\n",
        "  epoch_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  batch_number=1\n",
        "  \n",
        "  for batch in train_loader:\n",
        "    print(f'Epoch ({epoch+1}/{num_epochs}) -  Batch ({batch_number}/{len(train_loader)}])')   \n",
        "\n",
        "    #batch --> tuples(x,y)\n",
        "    # \"shape\" : (batch_size,2)\n",
        "    # x : list of n tensor (n=batch_size)\n",
        "    #x[i] : 1 x sample [ 1,  9, 10,  ...,  0,  0,  0]\n",
        "    x, y,_,_ = batch\n",
        "\n",
        "    # call of forward function and get the output\n",
        "    # shape [batch_size,vocab_size,seq_len] //torch.Size([64, 72, 26])\n",
        "    y_scores = morpho_inflection_model(batch=batch,forceTeaching=True)\n",
        "\n",
        "    \n",
        "    # compute loss\n",
        "    # input (y_scores) must be [batch_size,number_of_classes,seq_len]\n",
        "    # target (y) must be [batch_size,seq_len]\n",
        "    loss = cross_entropy_loss(y_scores, y)\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  \n",
        "    #backpropagation   \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    batch_number+=1\n",
        "    \n",
        "    \n",
        "\n",
        "  losses_epoch_train.append(epoch_loss/len(train_loader))\n",
        "  \n",
        "  morpho_inflection_model.eval()\n",
        "  torch.save(morpho_inflection_model, './model/model.pth')\n",
        "  np.save('./model/losses_epoch_train.npy', losses_epoch_train)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0mz6natT_9PS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "7897e8f2-01f8-4538-d724-36ac2d9b7259"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfrG8e+ThF5FIgIBgoAi0o30ImAHAQUV7CuoKEizrevu/nZd3YIFAQVF7IqoKIogRZHelN6V3gQp0pH+/P7IxI3ZgAFmcpLJ/bmuuZx5z5kzz5kLc8857znva+6OiIhIOMQEXYCIiEQPhYqIiISNQkVERMJGoSIiImGjUBERkbCJC7qAIBUvXtwTExODLkNEJFuZO3fuDnePT29Zjg6VxMRE5syZE3QZIiLZipmtP9kynf4SEZGwUaiIiEjYKFRERCRsFCoiIhI2ChUREQkbhYqIiISNQkVERMJGoXIGtu87zNOjlrF93+GgSxERyVIUKmdgxuodvDljHU36TKTP2BXsOXg06JJERLIEhcoZaFOzNF/1asIVVUowcNJqGvX5hv4TVrL/8LGgSxMRCZTl5Jkfk5KS/GyHaVm+ZS/Pj/+Br5f/RLECuXmgaQXuqF+OvLliw1SliEjWYmZz3T0p3WUKlfCM/bVg426eH/89U1fuoEThPHRrXolbksqQO04HgyISXRQqJxHOUEkxa81Onhv3PXPW76JMsXz0aHEhN9QqTWyMhfVzRESCcqpQ0c/oMKt3wbl83KU+b/7hMorky8UjHy/kqr6TGb1oCydO5NwAF5GcQaESAWZGs4vO44tujRh0W23MjK5D59FqwDS+WfETOfnoUESim0IlgsyMa6uVZFzPJrxwcw32Hz7GPW/Nod2gGcxYvSPo8kREwk59Kpk4SdfR4yf4aM5GBkxYxda9h2hY8Vwevuoiapc9J9NqEBE5W+qoP4nMDpUUh44e571Z6xk0aTU7DxyhReXzePiqi6hSqnCm1yIicroUKicRVKikOHD4GG9OX8urU9aw79AxWlYvSe8rL6RCfMHAahIR+T0KlZMIOlRS7Dl4lNemruGN6Ws5dPQ4N9ZOoEeLSpQplj/o0kRE/odC5SSySqik2LH/MIMmrebdWetxdzpcVpZuzStSonDeoEsTEfmVQuUkslqopNiy5xcGfLOKj77bSGyMcVeDRLo0rUCxArmDLk1ERKFyMlk1VFKs33mAfl+vZMSCzRTIHcc9jcrTuXF5CufNFXRpIpKDBXpHvZnFmtl8MxuVzrLeZrbMzBaZ2QQzKxdqb2ZmC1I9DplZ29AyM7NnzOwHM1tuZt1Ttfc3s1Wh7dWO9L5FWrlzC/DCLTUZ37MJjSsVp/+ElTT+z0QGTVrNwSMaEVlEsp7MuPmxB7D8JMvmA0nuXh0YDvQBcPeJ7l7T3WsCzYGDwPjQe+4GygCV3f1iYFio/VqgUuhxHzAo/LsSjEolCjHo9ksZ9VAjapUtyn/GrqBJn0m8NX0th48dD7o8EZFfRTRUzCwBaAkMSW95KDwOhl7OAhLSWa09MCbVeg8AT7n7idA2toXa2wDveLJZQFEzKxmmXckSqpYuwlt/qMPwLvWpEF+Av32xjObPTebTeZs0rpiIZAmRPlJ5EXgMOJGBdTsBY9Jp7wB8kOp1BeAWM5tjZmPMrFKovTSwMdV6m0Jtv2Fm94XeO2f79u0Z2YcsJymxGMPuq8e7nepQrEBuen+0kJYDpjHlh+y5PyISPSIWKmbWCtjm7nMzsO7tQBLwbJr2kkA1YFyq5jzAoVAn0WvAG6dTl7sPdvckd0+Kj48/nbdmKWZG40rxfN61If061GT/4aPc+ca33D5kNks27wm6PBHJoSJ5pNIQaG1m60ju92huZu+lXcnMrgCeBFq7++E0i28GRrh76kngNwGfhp6PAKqHnm8mua8lRUKoLarFxBhtapbm695N+UurKiz5cQ+tBkyj14cL2LTr4O9vQEQkjCIWKu7+hLsnuHsiyaewvnH321OvY2a1gFdJDpRt6WymI7899QXwGdAs9Lwp8EPo+UjgztBVYPWAPe6+JTx7k/XliYulU6PyTH60GQ9cXoEvF2+h+XOTeWb0MnYfPBJ0eSKSQ2T60Pdm9pSZtQ69fBYoCHwcunR4ZKr1Ekk+8picZhP/BtqZ2WLgX0DnUPuXwBpgFcmnxR6M1D5kZUXy5eLxayoz8ZHLaVOzFEOmraVJn4m8Onk1h47qSjERiSzd/JiFb34Mh+Vb9vKfsSuY9P12ShfNx8NXXUjbmqWJ0fTGInKGNJ1wDnZxycK89Yc6DO1cV1eKiUjEKVRyiAYVi+tKMRGJOIVKDqIrxUQk0tSnEuV9Kqey55ejvDJ5NW9MW4s73NWgHF2bVaRofo2GLCInp1GKTyKnh0qKH3f/Qt+vfmD4vE0UyhNH12YVuatBInlzxQZdmohkQeqol1MqVTQfz95Ugy+7N6Z2uXP415gVtHheY4qJyOlTqMivdKWYiJwthYr8D10pJiJnSqEi6dKVYiJyJtRRr476DNGVYiKSQld/nYRC5fTpSjER0dVfEjYpV4qN6dGYS1NdKTZivq4UExGFipyhyucX5s1UV4r1+nAhNwyawbwNu4IuTUQCpFCRs5JypdhzN9Vgy+5fuHHgDHoMm8+WPb8EXZqIBEChImctJsZof2kCEx+5nK7NKjBmyVaaPTeJF7/+gV+OaA4XkZxEoSJhUyBPHI9eXZkJvZvSonIJXvx6JS2en8TnCzaTky8IEclJFCoSdmWK5efl22rz4X31OKdAbnoMW0D7V2aycOPuoEsTkQhTqEjE1L3gXEZ2a8R/2lVj/c4DtHl5Og9/tJCf9h4KujQRiRCFikRUbIxxy2VlmfjI5dzf9AK+WPgjzZ6bxMsTV3HoqPpbRKKNQkUyRaG8uXji2ov5qncTGlcqzrPjvqfF85MZvWiL+ltEoohCRTJVuXML8OodSQztXJdCeePoOnQetwyepcEqRaKEQkUC0aBicUZ3b8wzN1Rl1bb9XP/SNB4fvojt+w4HXZqInAWFigQmNsa4rW45Jj5yOZ0alueTeZto9twkXpm8msPH1N8ikh0pVCRwRfLl4s+tqjC+VxPqli/Gv8es4Kq+Uxi3dKv6W0SyGYWKZBkXxBfk9bsv45176pA7Nob7353LbUNms2Lr3qBLE5EMUqhIltPkwnjG9GjMU20uYdmWvVzXbypPjljMzv3qbxHJ6hQqkiXFxcZwZ/1EJj1yOXfWT2TYdxu5/LlJDJm6hiPHTgRdnoichEJFsrSi+XPzt9aXMK5nY2qXPYenRy/nmhenMGH5T+pvEcmCFCqSLVQ8rxBv31OHN+++DAw6vT2HO9/4lpU/7Qu6NBFJRaEi2UqzyucxrmcT/tKqCgs37uaaflP5v8+XsOvAkaBLExEUKpIN5YqNoVOj8kx6tBkd65Th3Vnrufy5Sbw1fS1Hj6u/RSRIChXJtooVyM3TbavxZY/GVC1dmL99sYyW/acya83OoEsTybEUKpLtVT6/MO91qsurd1zKgcPH6TB4Fr0+XMC2fRpiXySzKVQkKpgZV19yPl/3bkq3ZhUZvWgLLZ6bzFvT13JMp8REMo1CRaJKvtyxPHL1RYzt2ZiaZYvyty+W0fql6cxdvyvo0kRyBIWKRKUL4gvyzj11GHhbbX4+cIR2g2bw2PCFuitfJMIUKhK1zIzrqpVkwsNNub/pBXw6bzPNn5/M+7PXc/yEbpwUiQSFikS9AnnieOLaixnTozEXlyzEkyOWcMPA6SzatDvo0kSiTsRDxcxizWy+mY1KZ1lvM1tmZovMbIKZlQu1NzOzBakeh8ysbWjZW2a2NtWymqH2y81sT6r2v0Z63yR7qVSiEB/cW49+HWqyZc8h2rw8nSdHLGb3Qd04KRIucZnwGT2A5UDhdJbNB5Lc/aCZPQD0AW5x94lASlgUA1YB41O971F3H57O9qa6e6uwVi9RxcxoU7M0zSufR9+vVvL2zHWMWbKVP15TmfaXJhATY0GXKJKtRfRIxcwSgJbAkPSWu/tEdz8YejkLSEhntfbAmFTriZy1Qnlz8dfrq/BFt0ZcULwAj32yiJtencnSH/cEXZpIthbp018vAo8BGblRoBMwJp32DsAHadqeCZ0y62tmeVK11zezhWY2xswuSe9DzOw+M5tjZnO2b9+ekX2QKFalVGE+ur8+z7avzrodB7h+wDT+NnIpew8dDbo0kWwpYqFiZq2Abe4+NwPr3g4kAc+maS8JVAPGpWp+AqgMXAYUAx4Ptc8Dyrl7DWAA8Fl6n+Xug909yd2T4uPjT2+nJCrFxBg3JZXhm4cv57a65Xh75jqaPzeZEfM3aXh9kdMUySOVhkBrM1sHDAOam9l7aVcysyuAJ4HW7p72JoKbgRHu/uvPRnff4skOA28CdULte919f+j5l0AuMysegf2SKFUkfy7+0bYqI7s2ovQ5+ej14UI6DJ7FDxpeXyTDIhYq7v6Euye4eyLJp7C+cffbU69jZrWAV0kOlG3pbKYjaU59hY5eMDMD2gJLQq/PD7VhZnVI3jeNLCinrVpCEUY80IB/3ViN73/ax3X9pvLM6GXsP3ws6NJEsrzMuPrrN8zsKWCOu48k+XRXQeDjUB5scPfWofUSgTLA5DSbeN/M4gEDFgBdQu3tgQfM7BjwC9DBde5CzlBMjNGxTlmuvuR8+oxdwWtT1zJy4Y/8pVUVWlYrSejfq4ikYTn5725SUpLPmTMn6DIkG5i3YRd/+WwJS3/cS6OKxfl7m0uoEF8w6LJEAmFmc909Kb1luqNeJANqlz2Hkd0a8VSbS1i4aTfXvDiFPmNXcPCITomJpKZQEcmg2BjjzvqJfPPw5bSuUZqBk1Zz5QtTGLd0q64SEwlRqIicpvhCeXj+5hp8dH99CuWN4/5353LPW9+xfueBoEsTCZxCReQM1SlfjC8easSfW17Md+t2cWXfKfT96gcOHT0edGkigVGoiJyFXLExdG58ARMebso1l5xPvwkruarvFCb/oNEaJGdSqIiEQYnCeenfsRZDO9clV6xx1xvf0nPYfE0KJjmOQkUkjBpULM6XPRrTvUUlRi/ewhUvTObTeRruRXIOhYpImOWJi6X3lRcyuntjyhcvQO+PFnLnG9+y8WcNtC3RT6EiEiEXlijE8C4NeKrNJcxbv4ur+k5hyNQ1HDuekUG7RbInhYpIBMWE7m35qndTGlY8l6dHL+eGgTM0b4tELYWKSCYoVTQfr92ZxMu31mbLnkO0fmk6/x6zQpcfS9RRqIhkEjOjZfWSTOjdlPa1E3hl8mqufnEKM1btCLo0kbBRqIhksiL5c/Gf9tUZem9dDLh1yGwe/Xghuw8eCbo0kbOmUBEJSIMKxRnbswkPXF6BT+dv5ooXJvPFwh91+bFkawoVkQDlzRXL49dUZmS3hpQqmo+HPphPp7fnsHn3L0GXJnJGFCoiWcAlpYrw6QMN+HPLi5m5eidXvTCZt6av5fgJHbVI9qJQEcki4kLjiI3v1YRLE4vxty+W0f6VGXy/dV/QpYlkmEJFJIspUyw/b//hMvreUoN1Ow7QasBUXhj/vS4/lmxBoSKSBZkZN9RK4OveTWlVvRT9v1nFdf2n8u3an4MuTeSUFCoiWdi5BfPQ95aavH1PHY4cO8HNr87kTyMWs/fQ0aBLE0lXhkLFzAqYWUzo+YVm1trMckW2NBFJ0fTCeMb3akLnRuUZ9u0Grnh+MmOXbA26LJH/kdEjlSlAXjMrDYwH7gDeilRRIvK/8ueO48+tqvBZ14acWzAPXd6bS5d35/LT3kNBlybyq4yGirn7QeBGYKC73wRcErmyRORkqicUZWS3hjx+TWUmfr+NK16YzNDZGzihy48lC8hwqJhZfeA2YHSoLTYyJYnI78kVG8MDl1dgXM8mVC1VhD+NWEyHwbNYvX1/0KVJDpfRUOkJPAGMcPelZnYBMDFyZYlIRiQWL8DQe+vSp311vv9pH9e+OJUBE1Zy5JjmbJFg2OmOMxTqsC/o7nsjU1LmSUpK8jlz5gRdhkhYbN93mL9/sZRRi7ZwUYlC/KtdNWqXPSfosiQKmdlcd09Kb1lGr/4aamaFzawAsARYZmaPhrNIETk78YXy8NKttXn9riT2HjpKu0EzeHrUMt00KZkqo6e/qoSOTNoCY4DyJF8BJiJZTIuLS/BV76bcWqcsQ6atpWX/qczfsCvosiSHyGio5Ardl9IWGOnuRwFdaiKSRRXME8czN1Tj3U51OHjkOO0GzaDP2BUcPqajFomsjIbKq8A6oAAwxczKAdm+T0Uk2jWuFM+4Xk1oVzuBgZNW0+al6SzZvCfosiSKnXZH/a9vNItz92NhridTqaNecpIJy3/ij58uZteBI3RrXpGuzSqSK1YjNcnpC0dHfREze8HM5oQez5N81CIi2USLi0vwVa8mtKxekhe/XskNA6drWH0Ju4z+THkD2AfcHHrsBd6MVFEiEhlF8+emX4davHJ7bbbsPsT1A6YxcNIqjh3XfS0SHhkNlQru/n/uvib0+DtwQSQLE5HIuaZqScb3akKLi8+jz9jvaf/KTN2NL2GR0VD5xcwapbwws4aAJtEWycbOLZiHgbfVpn/HWqzbeYDr+k1lyNQ1GkNMzkpcBtfrArxjZkVCr3cBd0WmJBHJLGZG6xqlqFe+GH8asZinRy9n/NKfePam6pQ7V92mcvoydKTi7gvdvQZQHaju7rWA5hGtTEQyzXmF8/LanUk8d1MNlm/dyzUvTuXdmet01CKn7bSuJ3T3vanG/OodgXpEJCBmRvtLExjfqwlJiefwl8+Xcscbs9m8W2e6JePO5iJ1y9BKZrFmNt/MRqWzrLeZLTOzRWY2IXRTJWbWzMwWpHocMrO2oWVvmdnaVMtqhtrNzPqb2arQ9mqfxb6J5Fgli+TjnXvq8M8bqrFgw26u7juFD7/bwJne0yY5y9mESkb/hfUAlp9k2Xwgyd2rA8OBPgDuPtHda7p7TZJPsx0kecbJFI+mLHf3BaG2a4FKocd9wKDT2hsR+ZWZcWvdsozt2YSqpQvz+CeLueet7zTLpPyuU4aKme0zs73pPPYBpX5v42aWALQEhqS3PBQeB0MvZwEJ6azWHhiTar2TaQO848lmAUXNrOTv1SgiJ1emWH6Gdq7H366vwsw1O7nyhcmMmL9JRy1yUqcMFXcv5O6F03kUcveMXDn2IvAYkJE7qzqRPAJyWh2AD9K0PRM6xdXXzPKE2koDG1OtsynU9htmdl/KyADbt2/PQFkiOVtMjHF3w/KM6dGESiUK0evDhdz/7ly27zscdGmSBUVs4B8zawVsc/e5GVj3diAJeDZNe0mgGjAuVfMTQGXgMqAY8Pjp1OXug909yd2T4uPjT+etIjla+eIF+Oj++vzpuspM+mE7V/WdzOhFW4IuS7KYSI4m1xBobWbrgGFAczN7L+1KZnYF8CTQ2t3T/vS5meQpjI+mNLj7ltAprsMkDxVTJ7RoM1Am1XsTQm0iEiaxMcZ9TSow+qFGlC2Wn65D59Ft6Dx+PnAk6NIki4hYqLj7E+6e4O6JJJ/C+sbdb0+9jpnVInlY/dbuvi2dzXQkzamvlH4SMzOS53dZElo0ErgzdBVYPWCPu+tnlEgEVCpRiE8eaMAjV13IuKVbuarvFMYv3Rp0WZIFZPq412b2lJm1Dr18FigIfBy6PHhkqvUSST7ymJxmE++b2WJgMVAceDrU/iWwBlgFvAY8GKl9EBGIi42hW/NKfN61EfGF8nDfu3Pp/dEC9vxy9PffLFHrjOdTiQaaT0UkPI4cO8FL36zk5UmriS+Yh3+3q8blF50XdFkSIWc9n4qIyKnkjouh91UXMeLBBhTKG8fdb37HE58uYv/hbD2Pn5wBhYqIhE31hKJ88VAjujStwIffbeTqvlOYsWpH0GVJJlKoiEhY5c0Vyx+vrczHXRqQJy6GW4fM5pnRyzh87HjQpUkmUKiISERcWu4cRndvzB31yvHa1LXcOHAGq7ZpIrBop1ARkYjJlzuWf7Stymt3JvHj7l9oNWAqQ2drcMpoplARkYi7skoJxvVswmWJyZOBdXlvLrt0w2RUUqiISKY4r3Be3v5DHf7c8mK+WbGNa/qpEz8aKVREJNPExBidG1/AiAcbUjBPHLe9Ppt/jVnOkWMZGXNWsgOFiohkuqqlizDqocZ0rFOWVyevod2gGazZrk78aKBQEZFA5Msdyz9vqMYrt1/Kxl0Hadl/mmaYjAIKFREJ1DVVz2dsjybUKluUxz9ZzIPvz2P3QXXiZ1cKFREJ3PlF8vJep7o8cW1lvlr2E9f2m8rM1TuDLkvOgEJFRLKEmBjj/qYVGPFgQ/LliuXWIbPoM3YFR4+rEz87UaiISJZSLaEIo7o34pakMgyctJr2g2awbseBoMuSDFKoiEiWkz93HP9uV51Bt9Vm3c6DXNd/Kh/P2ahO/GxAoSIiWda11UoypkdjqicU4dHhi+j2wXz2HNQkYFmZQkVEsrRSRfPxfud6PHr1RYxbspVr+03h27U/B12WnIRCRUSyvNgYo2uzinzyQANyx8XQYfBMnh//vTrxsyCFiohkGzXKFGV098a0q53AgG9WcdMrM1m/U534WYlCRUSylQJ54nj2phq8dGstVm/fz3X9pvLpvE3qxM8iFCoiki21ql6KsT2bcEmpIvT+aCE9hi1g7yF14gdNoSIi2Vbpovn44L56PHzlhYxevIVrX5zKnHXqxA+SQkVEsrXYGOOhFpX4uEt9YmOMm1+dSd+vfuCYOvEDoVARkahQu+w5jO7eiLY1S9NvwkpuGTyLjT8fDLqsHEehIiJRo1DeXLxwS036dajJD1v3cV2/qXy+YHPQZeUoChURiTptapbmyx6Nuej8QvQYtoBeHy5gnzrxM4VCRUSiUpli+Rl2Xz16XlGJzxdspmX/aSzZvCfosqKeQkVEolZcbAw9r7iQj7vU5+jxE9w4aAbvz16ve1oiSKEiIlHv0nLFGN29MfUuOJcnRyyh14cLOHD4WNBlRSWFiojkCMUK5Oatuy/j4SsvZOTCH2nz8nRW/rQv6LKijkJFRHKMmNA9Le91qsvug0do/dJ0Ppuvq8PCSaEiIjlOg4rFGd29MdVKF6Hnhwv404jFHDp6POiyooJCRURypBKF8zL03rp0aVqBobM30P6VGWzYqZslz5ZCRURyrLjYGP54bWWG3JnEhp0HaTlgKuOWbg26rGxNoSIiOd4VVUowuntjyhcvwP3vzuWZ0cs0AdgZUqiIiJB8s+THXepzR71yvDZ1LR0Hz2LLnl+CLivbUaiIiITkiYvlH22r0r9jLZZt2UvL/tOYunJ70GVlKwoVEZE0WtcoxchujSheMDd3vvEtfb/6geMndBd+RkQ8VMws1szmm9modJb1NrNlZrbIzCaYWblQezMzW5DqccjM2qZ5b38z25/q9d1mtj3VezpHet9EJHpVPK8gn3VtyA21kofSv+uNb9mx/3DQZWV5mXGk0gNYfpJl84Ekd68ODAf6ALj7RHev6e41gebAQWB8ypvMLAk4J53tfZjyPncfEs6dEJGcJ3/uOJ6/qQb/aVeN79b9TMv+U/lOM0ueUkRDxcwSgJZAun/gQ+GRcmH4LCAhndXaA2NS1jOzWOBZ4LHwVywi8ltmxi2XlWXEgw3JlyuWDoNnMXjKag1KeRKRPlJ5keQ//hm5Nq8TMCad9g7AB6ledwNGuvuWdNZtFzqVNtzMyqT3IWZ2n5nNMbM527erA05EMqZKqcKMfKgRV1UpwT+/XMF9785lzy+aoyWtiIWKmbUCtrn73AysezuQRPIRSOr2kkA1YFzodSngJmBAOpv5AkgMnUr7Cng7vc9y98HunuTuSfHx8aexRyKS0xXOm4uBt9Xmr62qMHHFNloNmMriTZqjJbVIHqk0BFqb2TpgGNDczN5Lu5KZXQE8CbR297S9YDcDI9w95edALaAisCq03fxmtgrA3Xemev8Q4NIw74+ICGbGPY3K81GX+hw/7rQbNIP3ZmmOlhQRCxV3f8LdE9w9keRTWN+4++2p1zGzWsCrJAfKtnQ205FUp77cfbS7n+/uiaHtHnT3iqFtlUz1vtac/OIAEZGzVrvsOYzq3pj6Fc7lz58toafmaAECuE/FzJ4ys9ahl88CBYGPQ5cBj0y1XiJQBpicwU13N7OlZrYQ6A7cHbaiRUTSUaxAbt68+zIeuepCvtAcLQBYTj5kS0pK8jlz5gRdhohEgRmrdtB92HwOHD7OP2+syg210ruYNTqY2Vx3T0pvme6oFxEJg1/naEkoQq8PF/LEpzlzjhaFiohImJQonJehnZPnaPng2w20GzSD9TsPBF1WplKoiIiEUcocLa/flcSmXb/QasA0xi7JOXO0KFRERCKgxcUlGPVQI8oXL0CX9+by9KicMUeLQkVEJEJS5mi5q345hkxbS4ccMEeLQkVEJILyxMXy9zZVGdCxFiu27OX6AdOielBKhYqISCa4vkYpPu/WkEJ5c3Hra7N4f/b6oEuKCIWKiEgmqXheIT7r2pAGFYrz5IglPDliMUeORVc/i0JFRCQTFcmXizfuvowuTSvw/uwN3DZkFtv3Rc/kXwoVEZFMFhtj/PHayvTrUJPFm/fQ+qVpUTPasUJFRCQgbWqWZniXBsSY0f6VGXy+YHPQJZ01hYqISICqli7C590aUqNMUXoMW8A/v1zO8RPZd0xGhYqISMCKF8zD+53rcke9cgyesoY/vPUdew5mz1klFSoiIllArtgY/tG2Kv+6sRozV++gzcvTsuUw+goVEZEspGOdsnxwbz32Hz7ODQNn8NWyn4Iu6bQoVEREspikxGJ88VBDLogvwL3vzKH/hJWcyCb9LAoVEZEsqGSRfHx0f31uqFWaF776ga5D52WL6YoVKiIiWVTeXLG8cHMN/tzyYsYt3Uq7QTPYsPNg0GWdkkJFRCQLMzM6N76At++pw5Y9h2j98jSmr9oRdFknpVAREckGGleK5/OuDYkvmIc73/iW16etxT3r9bMoVEREsonE4gUY0bUhLSqfxz9GLeORjxdx6OjxoMv6DYWKiEg2UjBPHAvSxUgAAAe6SURBVK/cfik9WlTik3mbuGXwLLbuORR0Wb9SqIiIZDMxMUavKy/kldsvZeVP+7j+pWnMXb8r6LIAhYqISLZ1TdXzGfFgQ/LliqXj4Fl89N3GoEtSqIiIZGcXnV+Ikd0aUveCYjz2ySL+7/MlHD0e3MRfChURkWyuaP7cvHn3ZXRuVJ63Z67njtdn8/OBI4HUolAREYkCcbEx/LlVFZ6/qQbzNuzm+gHTWPpj5k/8pVAREYki7S5N4OP763P8hNN+0ExGLfoxUz9foSIiEmVqlCnKyIcaUqVUYboNnU+fsSsybeIvhYqISBQ6r1Beht5blw6XlWHgpNXc+84c9h6K/MRfChURkSiVJy6Wf91YjX+0uYQpP2yn7cvTWb19f0Q/U6EiIhLFzIw76ifyXue67D54lLYvTWfiim0R+zyFiohIDlDvgnMZ2a0hZYrl5563v+ONaWsj8jkKFRGRHCLhnPx88kADWtcoRfn4AhH5jLiIbFVERLKkfLlj6dehVsS2ryMVEREJG4WKiIiETcRDxcxizWy+mY1KZ1lvM1tmZovMbIKZlQu1NzOzBakeh8ysbZr39jez/ale5zGzD81slZnNNrPESO+biIj8VmYcqfQAlp9k2Xwgyd2rA8OBPgDuPtHda7p7TaA5cBAYn/ImM0sCzkmzrU7ALnevCPQF/hPWvRARkd8V0VAxswSgJTAkveWh8DgYejkLSEhntfbAmJT1zCwWeBZ4LM16bYC3Q8+HAy3MzM5uD0RE5HRE+kjlRZL/+GdkcP9OwJh02jsAH6R63Q0Y6e5b0qxXGtgI4O7HgD3AuadbsIiInLmIXVJsZq2Abe4+18wu/511bweSgKZp2ksC1YBxodelgJuAU27vdz7rPuA+gLJly57pZkREJB2RPFJpCLQ2s3XAMKC5mb2XdiUzuwJ4Emjt7ofTLL4ZGOHuKaOg1QIqAqtC281vZqtCyzYDZULbjAOKADvTfp67D3b3JHdPio+PP8tdFBGR1Mw98sMhh45UHnH3Vmnaa5Hc/3GNu69M532zgCfcfeJJtrvf3QuGnncFqrl7FzPrANzo7jf/Tl3bgfVnsk9AcWDHGb43Gun7+C19H/+l7+K3ouH7KOfu6f4qz/Q76s3sKWCOu48kucO9IPBxqE99g7u3Dq2XSPKRx+QMbvp14N3QkcvPJPfFnNLJvpSMMLM57p50pu+PNvo+fkvfx3/pu/itaP8+MiVU3H0SMCn0/K+p2q84xXvWkdz5fqrtFkz1/BDJ/S0iIhIQ3VEvIiJho1A5c4ODLiCL0ffxW/o+/kvfxW9F9feRKR31IiKSM+hIRUREwkahIiIiYaNQOQNmdo2ZfR8aEfmPQdcTJDMrY2YTQ6NNLzWzHkHXFLRTjcyd05hZUTMbbmYrzGy5mdUPuqagmFmv0P8jS8zsAzPLG3RNkaBQOU2hAS1fBq4FqgAdzaxKsFUF6hjwsLtXAeoBXXP49wGnHpk7p+kHjHX3ykANcuj3Ymalge4kj8peFYglA/fSZUcKldNXB1jl7mvc/QjJQ9C0CbimwLj7FnefF3q+j+Q/Gqe8vyia/d7I3DmJmRUBmpB8YzLufsTddwdbVaDigHyhYaTyAz8GXE9EKFRO36+jIYdsIgf/EU0tNApCLWB2sJUE6nRG5o525YHtwJuh04FDzKxA0EUFwd03A88BG4AtwB53H3/qd2VPChUJCzMrCHwC9HT3vUHXE4TUI3MHXUsWEQfUBga5ey3gAJAj+yDN7BySz2iUB0oBBUKjs0cdhcrp+3U05JCEUFuOZWa5SA6U993906DrCVCGRubOQTYBm9w95ch1OMkhkxNdAax19+2hUdc/BRoEXFNEKFRO33dAJTMrb2a5Se5sGxlwTYEJza75OrDc3V8Iup4gufsT7p7g7okk/7v4xt2j8tdoRrj7VmCjmV0UamoBLAuwpCBtAOqZWf7Q/zMtiNKLFjJ9lOLszt2PmVk3kicOiwXecPelAZcVpIbAHcBiM1sQavuTu38ZYE2SdTwEvB/6AbYG+EPA9QTC3Web2XBgHslXTM4nSodr0TAtIiISNjr9JSIiYaNQERGRsFGoiIhI2ChUREQkbBQqIiISNgoVkQgys+NmtiDVI2x3lJtZopktCdf2RMJB96mIRNYv7l4z6CJEMouOVEQCYGbrzKyPmS02s2/NrGKoPdHMvjGzRWY2wczKhtpLmNkIM1sYeqQM8RFrZq+F5ukYb2b5AtspERQqIpGWL83pr1tSLdvj7tWAl0ge3RhgAPC2u1cH3gf6h9r7A5PdvQbJ42eljOJQCXjZ3S8BdgPtIrw/IqekO+pFIsjM9rt7wXTa1wHN3X1NaEDOre5+rpntAEq6+9FQ+xZ3L25m24EEdz+cahuJwFfuXin0+nEgl7s/Hfk9E0mfjlREguMneX46Dqd6fhz1k0rAFCoiwbkl1X9nhp7P4L/TzN4GTA09nwA8AMlTWodmVRTJcvSrRiSy8qUavRmS52tPuaz4HDNbRPLRRsdQ20Mkz5T4KMmzJqaM6tsDGGxmnUg+InmA5BkERbIU9amIBCDUp5Lk7juCrkUknHT6S0REwkZHKiIiEjY6UhERkbBRqIiISNgoVEREJGwUKiIiEjYKFRERCZv/B6sV0FJmTbg3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(num_epochs),losses_epoch_train, label='train')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "plt.savefig('./model/loss.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Evaluation"
      ],
      "metadata": {
        "id": "xeWPdCjiYaLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NJTd3ddOr_xc"
      },
      "outputs": [],
      "source": [
        "from torch import argmax\n",
        "\n",
        "train_dataset.create_dataset('./data/finnish-task1-dev')\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=my_custom_collate)\n",
        "\n",
        "emb_dim=10\n",
        "hidden_dim=50\n",
        "morpho_inflection_model = morphological_inflection_seq2seq(emb_dim, hidden_dim, train_dataset.vocab_size)\n",
        "\n",
        "morpho_inflection_model= torch.load('./model/model.pth')\n",
        "morpho_inflection_model.eval()\n",
        "\n",
        "f = open('./data/finnish-task1-dev-guess', 'w')\n",
        "    \n",
        "\n",
        "for batch in train_loader:\n",
        "  x, y,l,m = batch\n",
        "\n",
        "  #torch.Size([64, 72, 26])\n",
        "  y_scores = morpho_inflection_model(batch=batch,forceTeaching=False)\n",
        "    \n",
        "  prediction_string=''\n",
        "  for sample in range(len(x)):\n",
        "    #y_scores for one sample\n",
        "    y_sample=y_scores[sample]\n",
        "\n",
        "    prediction_id=torch.argmax(y_sample,0)\n",
        "    #print(prediction_id)\n",
        "    prediction_array=[train_dataset.id2token[p] for p in prediction_id]\n",
        "    prediction_string=''.join(prediction_array)\n",
        "    if prediction_string=='':\n",
        "      prediction_string='NULL'\n",
        "    f.write(l[sample]+'\\t'+m[sample]+'\\t'+prediction_string+'\\n')\n",
        "\n",
        "  \n",
        "f.close()  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python2.7 evalm.py --golden=./data/finnish-task1-dev --guesses=./data/finnish-task1-dev-guess"
      ],
      "metadata": {
        "id": "6xpqVJ26ZAbY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "METL_Inflection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO04zbkTySYj1B1zcr6Urpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}